{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geracao_pb_v6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmotta/Algebra-Linear-Python/blob/master/geracao_pb_v6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeckYjJCGnTP",
        "colab_type": "code",
        "outputId": "aa923106-63ce-4d33-8567-7f9aa8b20f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "!pip install tensorflow==1.8.0 \n",
        "#Importar o Tensorflow\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "from google.protobuf import text_format\n",
        "from tensorflow.python.platform import gfile\n",
        "from tensorflow.python.framework import graph_io\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "\n",
        "print(tf.__version__)\n",
        "#criação dos diretórios para salvar os checkpoints e o .pb\n",
        "save_dir = './checkpoint/'\n",
        "save_pb = './pb/'\n",
        "save_log = './log/'\n",
        "\n",
        "\n",
        "        \n",
        "# Para limpar as definições de variáveis e operações do grafo do tensorflow\n",
        "tf.reset_default_graph()        \n",
        "\n",
        "#inicia o tunelamento e mostrará um link\n",
        "#tbc=TensorBoardColab()\n",
        "\n",
        "#criação da base de dados\n",
        "x=np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]])#atributos previsores\n",
        "y=np.array([[0.],[1.],[1.],[0.]])#atributis da classe\n",
        "\n",
        "#definição das camadas\n",
        "neuronios_entrada = 2\n",
        "neuronios_oculta = 3\n",
        "neuronios_saida = 1\n",
        "\n",
        "#criação dos pesos das camadas de forma aleatória\n",
        "w = {'oculta' : tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta]), name='w_oculta',dtype=tf.float32),\n",
        "    'saida': tf.Variable(tf.random_normal([neuronios_oculta,neuronios_saida]), name='w_saida',dtype=tf.float32)}\n",
        "\n",
        "#criação dos bias das camadas de forma aleatória\n",
        "b = {'oculta' : tf.Variable(tf.random_normal([neuronios_oculta]), name='b_oculta',dtype=tf.float32),\n",
        "    'saida': tf.Variable(tf.random_normal([neuronios_saida]), name='b_saida',dtype=tf.float32)}\n",
        "\n",
        "#criação dos placesholders\n",
        "xph = tf.placeholder(tf.float32,[4, neuronios_entrada], name='xph')\n",
        "yph = tf.placeholder(tf.float32,[4, neuronios_saida], name='yph')\n",
        "\n",
        "#formulas\n",
        "camada_oculta = tf.add(tf.matmul(xph,w['oculta']),b['oculta'])\n",
        "camada_oculta_ativacao = tf.sigmoid(camada_oculta)\n",
        "camada_saida = tf.add(tf.matmul(camada_oculta_ativacao, w['saida']),b['saida'])\n",
        "camada_saida_ativacao = tf.sigmoid(camada_saida)\n",
        "erro = tf.losses.mean_squared_error(yph, camada_saida_ativacao)\n",
        "otimizador = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(erro)\n",
        "\n",
        "\n",
        "#cria os diretórios caso não existam\n",
        "#if not os.path.exists(save_dir):\n",
        "#    os.makedirs(save_dir)  \n",
        "    \n",
        "if not os.path.exists(save_pb):\n",
        "    os.makedirs(save_pb)\n",
        "    \n",
        "#cria inicialização para iniciar variáveis do tensorflow dentro da sessão \n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "#inicia sessão tensorflow\n",
        "with tf.Session() as sess:\n",
        "    #inicia as variáveis do tensorflow\n",
        "    sess.run(init)\n",
        "    #inicia o contador de épocas\n",
        "    epocas=0\n",
        "    #inicia o erro médio com valor alto para entrar no while\n",
        "    erro_medio = 999\n",
        "    #roda a rede até o erro for pequeno \n",
        "    while erro_medio >= 1e-2:\n",
        "        #inicia o erro médio com \n",
        "        erro_medio = 0\n",
        "        #inicia o feed dos placeholders e roda o otmizador e retorna o erro\n",
        "        _, custo =sess.run([otimizador, erro], feed_dict = {xph: x, yph: y})\n",
        "        #a cada 200 epocas ou o erro médio ser zero calcula o erro médio\n",
        "        if (epocas % 200 == 0) or (erro_medio == 0):\n",
        "            #calcula o erro médio para cada saída\n",
        "            erro_medio += custo/4\n",
        "            #incrementa as épocas\n",
        "            epocas+=1    \n",
        "            #print('Epoca: ', epocas, ' -> Erro Médio: ', erro_medio)\n",
        "    #salva os pesos finais e o bias final        \n",
        "    w_final, b_final = sess.run([w,b]) \n",
        "    \n",
        "    \n",
        "#criação da base de dados\n",
        "x=np.array([[0.,0.]])#atributos previsores\n",
        "y=np.array([[0.]])#atributos previsores\n",
        "    \n",
        "#criação dos placesholders\n",
        "xteste = tf.placeholder(tf.float32,[1, neuronios_entrada], name='xteste')\n",
        "output = tf.placeholder(tf.float32,[1, neuronios_saida], name='output')  \n",
        "\n",
        "#formulas teste de rede\n",
        "camada_oculta_teste = tf.add(tf.matmul(xteste,w_final['oculta']),b_final['oculta'])\n",
        "camada_oculta_ativacao_teste = tf.sigmoid(camada_oculta_teste)\n",
        "camada_saida_teste = tf.add(tf.matmul(camada_oculta_ativacao_teste, w_final['saida']),b_final['saida'])\n",
        "camada_saida_ativacao_teste = tf.sigmoid(camada_saida_teste)\n",
        "#print(camada_saida_ativacao_teste)\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    #execução da rede de teste\n",
        "    #print(sess.run(camada_saida_ativacao_teste, feed_dict=feed_dict_test))\n",
        "    output = sess.run(camada_saida_ativacao_teste)\n",
        "    print(output)# We use a built-in TF helper to export variables to constants\n",
        "      \n",
        "\n",
        "    #nome do arquivo de salvamento de log e faz a saida em formato .pbtxt\n",
        "    filename = 'my_test_model'\n",
        "       \n",
        "    # Exporta o checkpoint para SavedModel\n",
        "    #salva o grafo e eventos da sessão em arquivos de log \n",
        "    train_writer = tf.summary.FileWriter('./checkpoint/', sess.graph)\n",
        "    \n",
        "    # save the variable in the disk\n",
        "    saved_path = saver.save(sess, './checkpoint/'+filename+'.ckpt')\n",
        "    print('model saved in {}'.format(saved_path))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.4.1 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (1.16.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (0.33.4)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (1.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.4.1) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.1) (3.1.1)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.1) (1.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.1) (0.15.4)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.1) (0.9999999)\n",
            "1.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ee2a2b95be67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0merro_medio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m#inicia o feed dos placeholders e roda o otmizador e retorna o erro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcusto\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motimizador\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merro\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mxph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;31m#a cada 200 epocas ou o erro médio ser zero calcula o erro médio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepocas\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merro_medio\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeYRIcrKHD7i",
        "colab_type": "text"
      },
      "source": [
        "Geração dos nomes dos nós do grafo  para o congelamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaMPQjbI2lc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_node_names = []\n",
        "\n",
        "for op in tf.get_default_graph().get_operations():\n",
        "    #print(str(op.name))\n",
        "    output_node_names.append(str(op.name))\n",
        "print(output_node_names)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebwL97lVG-hX",
        "colab_type": "text"
      },
      "source": [
        "Função de Congelamento do Grafo completa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LwsTpAl2cOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The original freeze_graph function\n",
        "# from tensorflow.python.tools.freeze_graph import freeze_graph \n",
        "# For run in labview IMAQ DL Model Create VI keep constants equals zero\n",
        "#dir = os.path.dirname(os.path.realpath(__file__))\n",
        "\n",
        "def freeze_graph(model_dir, output_node_names, constants = 0):\n",
        "    \"\"\"Extract the sub graph defined by the output nodes and convert \n",
        "    all its variables into constant \n",
        "\n",
        "    Args:\n",
        "        model_dir: the root folder containing the checkpoint state file\n",
        "        output_node_names: a string, containing all the output node's names, \n",
        "                            comma separated\n",
        "    \"\"\"\n",
        "    if not tf.gfile.Exists(model_dir):\n",
        "        raise AssertionError(\n",
        "            \"Export directory doesn't exists. Please specify an export \"\n",
        "            \"directory: %s\" % model_dir)\n",
        "\n",
        "    if not output_node_names:\n",
        "        print(\"You need to supply the name of a node to --output_node_names.\")\n",
        "        return -1\n",
        "\n",
        "    # We retrieve our checkpoint fullpath\n",
        "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
        "    input_checkpoint = checkpoint.model_checkpoint_path\n",
        "    \n",
        "    # We precise the file fullname of our freezed graph\n",
        "    absolute_model_dir = \"/\".join(input_checkpoint.split('/')[:-1])\n",
        "    output_graph = absolute_model_dir + \"/frozen_model.pb\"\n",
        "\n",
        "    # We clear devices to allow TensorFlow to control on which device it will load operations\n",
        "    clear_devices = True\n",
        "\n",
        "    # We start a session using a temporary fresh Graph\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        # We import the meta graph in the current default Graph\n",
        "        saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
        "\n",
        "        # We restore the weights\n",
        "        saver.restore(sess, input_checkpoint)\n",
        "        \n",
        "        if constants == 1:\n",
        "            print(\"constantes\")\n",
        "            # We use a built-in TF helper to export variables to constants\n",
        "            output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
        "                sess, # The session is used to retrieve the weights\n",
        "                tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
        "                output_node_names # The output node names are used to select the usefull nodes\n",
        "            )\n",
        "        else:\n",
        "            print('variaveis')\n",
        "            output_graph_def = tf.get_default_graph().as_graph_def()\n",
        "\n",
        "        # Finally we serialize and dump the output graph to the filesystem\n",
        "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "            f.write(output_graph_def.SerializeToString())\n",
        "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
        "\n",
        "    return output_graph_def\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "motbSf6y2-3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freeze_graph('./checkpoint/', output_node_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbzdFB8DG0pF",
        "colab_type": "text"
      },
      "source": [
        "Gera o .pb Separada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K2XIByr47uH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)  \n",
        "    #exporta para formato .pb\n",
        "    tf.train.write_graph(tf.GraphDef(), save_pb,filename+'.pb', as_text=False)\n",
        "    test_summary_writer = tf.summary.FileWriter(save_log, sess.graph) \n",
        "    train_writer.add_graph(sess.graph)\n",
        "    train_writer.flush();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q7jdevxGrub",
        "colab_type": "text"
      },
      "source": [
        "Função de congelamento separada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeLYXoOvAxM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    #congela variaveis\n",
        "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
        "        sess, # The session is used to retrieve the weights\n",
        "        tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
        "        output_node_names# The output node names are used to select the usefull nodes\n",
        "    ) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}