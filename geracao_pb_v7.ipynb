{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geracao_pb_v7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmotta/Algebra-Linear-Python/blob/master/geracao_pb_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeckYjJCGnTP",
        "colab_type": "code",
        "outputId": "44b030e1-d964-49b4-cc0a-29cd28f491d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "!pip install tensorflow==1.8.0\n",
        "#Importar o Tensorflow\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "from google.protobuf import text_format\n",
        "from tensorflow.python.platform import gfile\n",
        "from tensorflow.python.framework import graph_io\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "\n",
        "#reset runtimes\n",
        "def restart_runtime():\n",
        "  os.kill(os.getpid(), 9)\n",
        "\n",
        "print('Versão do TensorFlow: ',tf.__version__)\n",
        "#criação dos diretórios para salvar os checkpoints e o .pb\n",
        "save_dir = './checkpoint/'\n",
        "save_pb = './pb/'\n",
        "save_log = './log/'     \n",
        "\n",
        "#inicia o tunelamento e mostrará um link\n",
        "#tbc=TensorBoardColab()\n",
        "\n",
        "#criação da base de dados\n",
        "x=np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]])#atributos previsores\n",
        "y=np.array([[0.],[1.],[1.],[0.]])#atributis da classe\n",
        "\n",
        "#definição das camadas\n",
        "neuronios_entrada = 2\n",
        "neuronios_oculta = 3\n",
        "neuronios_saida = 1\n",
        "\n",
        "#criação dos pesos das camadas de forma aleatória\n",
        "w = {'oculta' : tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta]), name='w_oculta',dtype=tf.float32),\n",
        "    'saida': tf.Variable(tf.random_normal([neuronios_oculta,neuronios_saida]), name='w_saida',dtype=tf.float32)}\n",
        "\n",
        "#criação dos bias das camadas de forma aleatória\n",
        "b = {'oculta' : tf.Variable(tf.random_normal([neuronios_oculta]), name='b_oculta',dtype=tf.float32),\n",
        "    'saida': tf.Variable(tf.random_normal([neuronios_saida]), name='b_saida',dtype=tf.float32)}\n",
        "\n",
        "#criação dos placesholders\n",
        "xph = tf.placeholder(tf.float32,[4, neuronios_entrada], name='xph')\n",
        "yph = tf.placeholder(tf.float32,[4, neuronios_saida], name='yph')\n",
        "\n",
        "#formulas\n",
        "camada_oculta = tf.add(tf.matmul(xph,w['oculta']),b['oculta'])\n",
        "camada_oculta_ativacao = tf.sigmoid(camada_oculta)\n",
        "camada_saida = tf.add(tf.matmul(camada_oculta_ativacao, w['saida']),b['saida'])\n",
        "camada_saida_ativacao = tf.sigmoid(camada_saida)\n",
        "erro = tf.losses.mean_squared_error(yph, camada_saida_ativacao)\n",
        "otimizador = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(erro)\n",
        "\n",
        "\n",
        "#cria os diretórios caso não existam\n",
        "#if not os.path.exists(save_dir):\n",
        "#    os.makedirs(save_dir)  \n",
        "    \n",
        "if not os.path.exists(save_pb):\n",
        "    os.makedirs(save_pb)\n",
        "    \n",
        "#cria inicialização para iniciar variáveis do tensorflow dentro da sessão \n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "#inicia sessão tensorflow\n",
        "with tf.Session() as sess:\n",
        "    #inicia as variáveis do tensorflow\n",
        "    sess.run(init)\n",
        "    #inicia o contador de épocas\n",
        "    epocas=0\n",
        "    #inicia o erro médio com valor alto para entrar no while\n",
        "    erro_medio = 1\n",
        "    #roda a rede até o erro for pequeno \n",
        "    while erro_medio >= 1e-5:\n",
        "        #inicia o erro médio com \n",
        "        erro_medio = 0\n",
        "        #inicia o feed dos placeholders e roda o otmizador e retorna o erro\n",
        "        _, custo =sess.run([otimizador, erro], feed_dict = {xph: x, yph: y})\n",
        "        #a cada 200 epocas ou o erro médio ser zero calcula o erro médio\n",
        "        if (epocas % 200 == 0) or (erro_medio == 0):\n",
        "            #calcula o erro médio para cada saída\n",
        "            erro_medio += custo/4\n",
        "            #incrementa as épocas\n",
        "            epocas+=1    \n",
        "            #print('Epoca: ', epocas, ' -> Erro Médio: ', erro_medio)\n",
        "    #salva os pesos finais e o bias final        \n",
        "    w_final, b_final = sess.run([w,b]) \n",
        "    \n",
        "        \n",
        "# Para limpar as definições de variáveis e operações do grafo do tensorflow\n",
        "tf.reset_default_graph()   \n",
        "\n",
        "#criação da base de dados\n",
        "x=np.array([[0.,0.]])#atributos previsores\n",
        "y=np.array([[0.]])#atributos previsores\n",
        "    \n",
        "#criação dos placesholders\n",
        "xteste = tf.placeholder(tf.float32,[1, neuronios_entrada], name='xteste')\n",
        "#output = tf.placeholder(tf.float32,[1, neuronios_saida], name='output')  \n",
        "\n",
        "#formulas teste de rede\n",
        "camada_oculta_teste = tf.add(tf.matmul(xteste,w_final['oculta']),b_final['oculta'])\n",
        "camada_oculta_ativacao_teste = tf.sigmoid(camada_oculta_teste)\n",
        "camada_saida_teste = tf.add(tf.matmul(camada_oculta_ativacao_teste, w_final['saida']),b_final['saida'])\n",
        "camada_saida_ativacao_teste = tf.sigmoid(camada_saida_teste, name=\"output\")\n",
        "#print(camada_saida_ativacao_teste)\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "feed_dict_test = {xteste: x}\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    #execução da rede de teste\n",
        "    #print(sess.run(camada_saida_ativacao_teste, feed_dict=feed_dict_test))\n",
        "    #output = sess.run(camada_saida_ativacao_teste, feed_dict=feed_dict_test)\n",
        "    sess.run(camada_saida_ativacao_teste, feed_dict=feed_dict_test)\n",
        "    #print(tf.get_default_graph().get_operations())\n",
        "    #print(list(a.op.outputs))   \n",
        "    print(camada_saida_ativacao_teste.op.outputs)\n",
        "    \n",
        "    #nome do arquivo de salvamento de log e faz a saida em formato .pbtxt\n",
        "    filename = 'my_test_model'\n",
        "       \n",
        "    # Exporta o checkpoint para SavedModel\n",
        "    #salva o grafo e eventos da sessão em arquivos de log \n",
        "    train_writer = tf.summary.FileWriter('./checkpoint/', sess.graph)\n",
        "    \n",
        "    # save the variable in the disk\n",
        "    saved_path = saver.save(sess, './checkpoint/'+filename+'.ckpt')\n",
        "    print('model saved in {}'.format(saved_path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (49.1MB)\n",
            "\u001b[K     |████████████████████████████████| 49.1MB 708kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.2.2)\n",
            "Collecting tensorboard<1.9.0,>=1.8.0 (from tensorflow==1.8.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.16.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8.0) (41.0.1)\n",
            "Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.6MB/s \n",
            "\u001b[?25hCollecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (0.15.4)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: html5lib, bleach, tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.0\n",
            "    Uninstalling bleach-3.1.0:\n",
            "      Successfully uninstalled bleach-3.1.0\n",
            "  Found existing installation: tensorboard 1.14.0\n",
            "    Uninstalling tensorboard-1.14.0:\n",
            "      Successfully uninstalled tensorboard-1.14.0\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.8.0 tensorflow-1.8.0\n",
            "Versão do TensorFlow:  1.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeYRIcrKHD7i",
        "colab_type": "text"
      },
      "source": [
        "Geração dos nomes dos nós do grafo  para o congelamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaMPQjbI2lc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_node_names = []\n",
        "\n",
        "for op in tf.get_default_graph().get_operations():\n",
        "    #print(str(op.name))\n",
        "    output_node_names.append(str(op.name))\n",
        "print(output_node_names)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebwL97lVG-hX",
        "colab_type": "text"
      },
      "source": [
        "Função de Congelamento do Grafo completa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LwsTpAl2cOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The original freeze_graph function\n",
        "# from tensorflow.python.tools.freeze_graph import freeze_graph \n",
        "# For run in labview IMAQ DL Model Create VI keep constants equals zero\n",
        "#dir = os.path.dirname(os.path.realpath(__file__))\n",
        "\n",
        "def freeze_graph(model_dir, output_node_names, constants = 0):\n",
        "    \"\"\"Extract the sub graph defined by the output nodes and convert \n",
        "    all its variables into constant \n",
        "\n",
        "    Args:\n",
        "        model_dir: the root folder containing the checkpoint state file\n",
        "        output_node_names: a string, containing all the output node's names, \n",
        "                            comma separated\n",
        "    \"\"\"\n",
        "    if not tf.gfile.Exists(model_dir):\n",
        "        raise AssertionError(\n",
        "            \"Export directory doesn't exists. Please specify an export \"\n",
        "            \"directory: %s\" % model_dir)\n",
        "\n",
        "    if not output_node_names:\n",
        "        print(\"You need to supply the name of a node to --output_node_names.\")\n",
        "        return -1\n",
        "\n",
        "    # We retrieve our checkpoint fullpath\n",
        "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
        "    input_checkpoint = checkpoint.model_checkpoint_path\n",
        "    \n",
        "    # We precise the file fullname of our freezed graph\n",
        "    absolute_model_dir = \"/\".join(input_checkpoint.split('/')[:-1])\n",
        "    output_graph = absolute_model_dir + \"/frozen_model.pb\"\n",
        "\n",
        "    # We clear devices to allow TensorFlow to control on which device it will load operations\n",
        "    clear_devices = True\n",
        "\n",
        "    # We start a session using a temporary fresh Graph\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        # We import the meta graph in the current default Graph\n",
        "        saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
        "\n",
        "        # We restore the weights\n",
        "        saver.restore(sess, input_checkpoint)\n",
        "        \n",
        "        if constants == 1:\n",
        "            print(\"constantes\")\n",
        "            # We use a built-in TF helper to export variables to constants\n",
        "            output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
        "                sess, # The session is used to retrieve the weights\n",
        "                tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
        "                output_node_names # The output node names are used to select the usefull nodes\n",
        "            )\n",
        "        else:\n",
        "            print('variaveis')\n",
        "            output_graph_def = tf.get_default_graph().as_graph_def()\n",
        "\n",
        "        # Finally we serialize and dump the output graph to the filesystem\n",
        "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "            f.write(output_graph_def.SerializeToString())\n",
        "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
        "\n",
        "    return output_graph_def\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "motbSf6y2-3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freeze_graph('./checkpoint/', output_node_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTed-oCiaDM_",
        "colab_type": "text"
      },
      "source": [
        "Mostra .PB no TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mDje0g8aB0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importar o Tensorflow\n",
        "import tensorflow as tf\n",
        "!pip install --ignore-installed tf-nightly\n",
        "from google.colab import files\n",
        "\n",
        "def run_tensorboard(model_filename=''):\n",
        "\n",
        "    #model_filename ='/content/frozen_model.pb'\n",
        "    if  model_filename == '':\n",
        "        uploaded = files.upload()   \n",
        "\n",
        "    from tensorflow.python.platform import gfile\n",
        "    with tf.Session() as sess:\n",
        "       \n",
        "        with gfile.FastGFile(model_filename, 'rb') as f:\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(f.read())\n",
        "            g_in = tf.import_graph_def(graph_def)\n",
        "    LOGDIR='/content/logs'\n",
        "    train_writer = tf.summary.FileWriter(LOGDIR)\n",
        "    train_writer.add_graph(sess.graph)\n",
        "\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./logs\n",
        "run_tensorboard('/content/checkpoint/frozen_model.pb')   \n",
        "#run_tensorboard('/content/checkpoint/frozen_inference_SSDMobilenetV1_graph.pb') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}