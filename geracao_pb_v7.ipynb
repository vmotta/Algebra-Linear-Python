{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geracao_pb_v7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmotta/Algebra-Linear-Python/blob/master/geracao_pb_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeckYjJCGnTP",
        "colab_type": "code",
        "outputId": "74ccd1ef-bd18-45e1-8c40-70cd19082e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "source": [
        "!pip install tensorflow==1.8.0\n",
        "#Importar o Tensorflow\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "from google.protobuf import text_format\n",
        "from tensorflow.python.platform import gfile\n",
        "from tensorflow.python.framework import graph_io\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "\n",
        "#reset runtimes\n",
        "def restart_runtime():\n",
        "  os.kill(os.getpid(), 9)\n",
        "\n",
        "print('Versão do TensorFlow: ',tf.__version__)\n",
        "#criação dos diretórios para salvar os checkpoints e o .pb\n",
        "save_dir = './checkpoint/'\n",
        "save_pb = './pb/'\n",
        "save_log = './log/'     \n",
        "\n",
        "#inicia o tunelamento e mostrará um link\n",
        "#tbc=TensorBoardColab()\n",
        "\n",
        "#criação da base de dados\n",
        "x=np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]])#atributos previsores\n",
        "y=np.array([[0.],[1.],[1.],[0.]])#atributis da classe\n",
        "\n",
        "#definição das camadas\n",
        "neuronios_entrada = 2\n",
        "neuronios_oculta = 3\n",
        "neuronios_saida = 1\n",
        "\n",
        "#criação dos pesos das camadas de forma aleatória\n",
        "w = {'oculta' : tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta]), name='w_oculta',dtype=tf.float32),\n",
        "    'saida': tf.Variable(tf.random_normal([neuronios_oculta,neuronios_saida]), name='w_saida',dtype=tf.float32)}\n",
        "\n",
        "#criação dos bias das camadas de forma aleatória\n",
        "b = {'oculta' : tf.Variable(tf.random_normal([neuronios_oculta]), name='b_oculta',dtype=tf.float32),\n",
        "    'saida': tf.Variable(tf.random_normal([neuronios_saida]), name='b_saida',dtype=tf.float32)}\n",
        "\n",
        "#criação dos placesholders\n",
        "xph = tf.placeholder(tf.float32,[4, neuronios_entrada], name='xph')\n",
        "yph = tf.placeholder(tf.float32,[4, neuronios_saida], name='yph')\n",
        "\n",
        "#formulas\n",
        "camada_oculta = tf.add(tf.matmul(xph,w['oculta']),b['oculta'])\n",
        "camada_oculta_ativacao = tf.sigmoid(camada_oculta)\n",
        "camada_saida = tf.add(tf.matmul(camada_oculta_ativacao, w['saida']),b['saida'])\n",
        "camada_saida_ativacao = tf.sigmoid(camada_saida)\n",
        "erro = tf.losses.mean_squared_error(yph, camada_saida_ativacao)\n",
        "otimizador = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(erro)\n",
        "\n",
        "\n",
        "#cria os diretórios caso não existam\n",
        "#if not os.path.exists(save_dir):\n",
        "#    os.makedirs(save_dir)  \n",
        "    \n",
        "if not os.path.exists(save_pb):\n",
        "    os.makedirs(save_pb)\n",
        "    \n",
        "#cria inicialização para iniciar variáveis do tensorflow dentro da sessão \n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "#inicia sessão tensorflow\n",
        "with tf.Session() as sess:\n",
        "    #inicia as variáveis do tensorflow\n",
        "    sess.run(init)\n",
        "    #inicia o contador de épocas\n",
        "    epocas=0\n",
        "    #inicia o erro médio com valor alto para entrar no while\n",
        "    erro_medio = 1\n",
        "    #roda a rede até o erro for pequeno \n",
        "    while erro_medio >= 1e-2:\n",
        "        #inicia o erro médio com \n",
        "        erro_medio = 0\n",
        "        #inicia o feed dos placeholders e roda o otmizador e retorna o erro\n",
        "        _, custo =sess.run([otimizador, erro], feed_dict = {xph: x, yph: y})\n",
        "        #a cada 200 epocas ou o erro médio ser zero calcula o erro médio\n",
        "        if (epocas % 200 == 0) or (erro_medio == 0):\n",
        "            #calcula o erro médio para cada saída\n",
        "            erro_medio += custo/4\n",
        "            #incrementa as épocas\n",
        "            epocas+=1    \n",
        "            #print('Epoca: ', epocas, ' -> Erro Médio: ', erro_medio)\n",
        "    #salva os pesos finais e o bias final        \n",
        "    w_final, b_final = sess.run([w,b]) \n",
        "    \n",
        "        \n",
        "# Para limpar as definições de variáveis e operações do grafo do tensorflow\n",
        "tf.reset_default_graph()   \n",
        "\n",
        "#criação da base de dados\n",
        "x=np.array([[0.,0.]])#atributos previsores\n",
        "y=np.array([[0.]])#atributos previsores\n",
        "    \n",
        "#criação dos placesholders\n",
        "xteste = tf.placeholder(tf.float32,[1, neuronios_entrada], name='xteste')\n",
        "#output = tf.placeholder(tf.float32,[1, neuronios_saida], name='output')  \n",
        "\n",
        "#formulas teste de rede\n",
        "camada_oculta_teste = tf.add(tf.matmul(xteste,w_final['oculta']),b_final['oculta'])\n",
        "camada_oculta_ativacao_teste = tf.sigmoid(camada_oculta_teste)\n",
        "camada_saida_teste = tf.add(tf.matmul(camada_oculta_ativacao_teste, w_final['saida']),b_final['saida'])\n",
        "camada_saida_ativacao_teste = tf.sigmoid(camada_saida_teste, name=\"output\")\n",
        "#print(camada_saida_ativacao_teste)\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "feed_dict_test = {xteste: x}\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    #execução da rede de teste\n",
        "    #print(sess.run(camada_saida_ativacao_teste, feed_dict=feed_dict_test))\n",
        "    #output = sess.run(camada_saida_ativacao_teste, feed_dict=feed_dict_test)\n",
        "    sess.run(camada_saida_ativacao_teste, feed_dict=feed_dict_test)\n",
        "    #print(tf.get_default_graph().get_operations())\n",
        "    #print(list(a.op.outputs))   \n",
        "    print(camada_saida_ativacao_teste.op.outputs)\n",
        "    \n",
        "    #nome do arquivo de salvamento de log e faz a saida em formato .pbtxt\n",
        "    filename = 'my_test_model'\n",
        "       \n",
        "    # Exporta o checkpoint para SavedModel\n",
        "    #salva o grafo e eventos da sessão em arquivos de log \n",
        "    train_writer = tf.summary.FileWriter('./checkpoint/', sess.graph)\n",
        "    \n",
        "    # save the variable in the disk\n",
        "    saved_path = saver.save(sess, './checkpoint/'+filename+'.ckpt')\n",
        "    print('model saved in {}'.format(saved_path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.8.0 in /usr/local/lib/python3.6/dist-packages (1.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.8.0)\n",
            "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.16.4)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (3.7.1)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (0.9999999)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (3.1.1)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (1.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (0.15.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8.0) (41.0.1)\n",
            "Versão do TensorFlow:  1.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d43d98bae32d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mfeed_dict_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mxteste\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1336\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m   1370\u001b[0m           \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No variables to save"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeYRIcrKHD7i",
        "colab_type": "text"
      },
      "source": [
        "Geração dos nomes dos nós do grafo  para o congelamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaMPQjbI2lc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_node_names = []\n",
        "\n",
        "for op in tf.get_default_graph().get_operations():\n",
        "    #print(str(op.name))\n",
        "    output_node_names.append(str(op.name))\n",
        "print(output_node_names)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebwL97lVG-hX",
        "colab_type": "text"
      },
      "source": [
        "Função de Congelamento do Grafo completa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LwsTpAl2cOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The original freeze_graph function\n",
        "# from tensorflow.python.tools.freeze_graph import freeze_graph \n",
        "# For run in labview IMAQ DL Model Create VI keep constants equals zero\n",
        "#dir = os.path.dirname(os.path.realpath(__file__))\n",
        "\n",
        "def freeze_graph(model_dir, output_node_names, constants = 0):\n",
        "    \"\"\"Extract the sub graph defined by the output nodes and convert \n",
        "    all its variables into constant \n",
        "\n",
        "    Args:\n",
        "        model_dir: the root folder containing the checkpoint state file\n",
        "        output_node_names: a string, containing all the output node's names, \n",
        "                            comma separated\n",
        "    \"\"\"\n",
        "    if not tf.gfile.Exists(model_dir):\n",
        "        raise AssertionError(\n",
        "            \"Export directory doesn't exists. Please specify an export \"\n",
        "            \"directory: %s\" % model_dir)\n",
        "\n",
        "    if not output_node_names:\n",
        "        print(\"You need to supply the name of a node to --output_node_names.\")\n",
        "        return -1\n",
        "\n",
        "    # We retrieve our checkpoint fullpath\n",
        "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
        "    input_checkpoint = checkpoint.model_checkpoint_path\n",
        "    \n",
        "    # We precise the file fullname of our freezed graph\n",
        "    absolute_model_dir = \"/\".join(input_checkpoint.split('/')[:-1])\n",
        "    output_graph = absolute_model_dir + \"/frozen_model.pb\"\n",
        "\n",
        "    # We clear devices to allow TensorFlow to control on which device it will load operations\n",
        "    clear_devices = True\n",
        "\n",
        "    # We start a session using a temporary fresh Graph\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        # We import the meta graph in the current default Graph\n",
        "        saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
        "\n",
        "        # We restore the weights\n",
        "        saver.restore(sess, input_checkpoint)\n",
        "        \n",
        "        if constants == 1:\n",
        "            print(\"constantes\")\n",
        "            # We use a built-in TF helper to export variables to constants\n",
        "            output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
        "                sess, # The session is used to retrieve the weights\n",
        "                tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
        "                output_node_names # The output node names are used to select the usefull nodes\n",
        "            )\n",
        "        else:\n",
        "            print('variaveis')\n",
        "            output_graph_def = tf.get_default_graph().as_graph_def()\n",
        "\n",
        "        # Finally we serialize and dump the output graph to the filesystem\n",
        "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "            f.write(output_graph_def.SerializeToString())\n",
        "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
        "\n",
        "    return output_graph_def\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "motbSf6y2-3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freeze_graph('./checkpoint/', output_node_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTed-oCiaDM_",
        "colab_type": "text"
      },
      "source": [
        "Mostra .PB no TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mDje0g8aB0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importar o Tensorflow\n",
        "import tensorflow as tf\n",
        "!pip install --ignore-installed tf-nightly\n",
        "from google.colab import files\n",
        "\n",
        "def run_tensorboard(model_filename=''):\n",
        "\n",
        "    #model_filename ='/content/frozen_model.pb'\n",
        "    if  model_filename == '':\n",
        "        uploaded = files.upload()   \n",
        "\n",
        "    from tensorflow.python.platform import gfile\n",
        "    with tf.Session() as sess:\n",
        "       \n",
        "        with gfile.FastGFile(model_filename, 'rb') as f:\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(f.read())\n",
        "            g_in = tf.import_graph_def(graph_def)\n",
        "    LOGDIR='/content/logs'\n",
        "    train_writer = tf.summary.FileWriter(LOGDIR)\n",
        "    train_writer.add_graph(sess.graph)\n",
        "\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./logs\n",
        "run_tensorboard('/content/checkpoint/frozen_model.pb')   \n",
        "#run_tensorboard('/content/checkpoint/frozen_inference_SSDMobilenetV1_graph.pb') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}