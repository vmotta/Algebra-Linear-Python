{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geracao_pb_v4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmotta/Algebra-Linear-Python/blob/master/geracao_pb_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO_tjZsjs7v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importar o Tensorflow\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.protobuf import text_format\n",
        "\n",
        "#criação dos diretórios para salvar os checkpoints e o .pb\n",
        "save_dir = './checkpoints/'\n",
        "save_pb = './pb/'\n",
        "save_log = './log/'\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHF7ixrNofCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "741b0bee-65e0-4fc0-b075-8c6ed315df32"
      },
      "source": [
        "#Importar o Tensorflow\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.protobuf import text_format\n",
        "\n",
        "#criação dos diretórios para salvar os checkpoints e o .pb\n",
        "save_dir = './checkpoints/'\n",
        "save_pb = './pb/'\n",
        "save_log = './log/'\n",
        "\n",
        "\n",
        "        \n",
        "# Para limpar as definições de variáveis e operações do grafo do tensorflow\n",
        "tf.reset_default_graph()          \n",
        "\n",
        "#criação da base de dados\n",
        "x=np.array([[0,0],[0,1],[1,0],[1,1]])#atributos previsores\n",
        "y=np.array([[0],[1],[1],[0]])#atributis da classe\n",
        "\n",
        "#definição das camadas\n",
        "neuronios_entrada = 2\n",
        "neuronios_oculta = 3\n",
        "neuronios_saida = 1\n",
        "\n",
        "#criação dos pesos das camadas de forma aleatória\n",
        "w = {'oculta' : tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta]), name='w_oculta'),\n",
        "    'saida': tf.Variable(tf.random_normal([neuronios_oculta,neuronios_saida]), name='w_saida')}\n",
        "\n",
        "#criação dos bias das camadas de forma aleatória\n",
        "b = {'oculta' : tf.Variable(tf.random_normal([neuronios_oculta]), name='b_oculta'),\n",
        "    'saida': tf.Variable(tf.random_normal([neuronios_saida]), name='b_saida')}\n",
        "\n",
        "#criação dos placesholders\n",
        "xph = tf.placeholder(tf.float32,[4, neuronios_entrada], name='xph')\n",
        "yph = tf.placeholder(tf.float32,[4, neuronios_saida], name='yph')\n",
        "\n",
        "#formulas\n",
        "camada_oculta = tf.add(tf.matmul(xph,w['oculta']),b['oculta'])\n",
        "camada_oculta_ativacao = tf.sigmoid(camada_oculta)\n",
        "camada_saida = tf.add(tf.matmul(camada_oculta_ativacao, w['saida']),b['saida'])\n",
        "camada_saida_ativacao = tf.sigmoid(camada_saida)\n",
        "erro = tf.losses.mean_squared_error(yph, camada_saida_ativacao)\n",
        "otimizador = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(erro)\n",
        "\n",
        "\n",
        "#cria os diretórios caso não existam\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)  \n",
        "if not os.path.exists(save_pb):\n",
        "    os.makedirs(save_pb)\n",
        "    \n",
        "#cria inicialização para iniciar variáveis do tensorflow dentro da sessão \n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "#inicia sessão tensorflow\n",
        "with tf.Session() as sess:\n",
        "    #inicia as variáveis do tensorflow\n",
        "    sess.run(init)\n",
        "    #inicia o contador de épocas\n",
        "    epocas=0\n",
        "    #inicia o erro médio com valor alto para entrar no while\n",
        "    erro_medio = 999\n",
        "    #roda a rede até o erro for pequeno \n",
        "    while erro_medio >= 1e-2:\n",
        "        #inicia o erro médio com \n",
        "        erro_medio = 0\n",
        "        #inicia o feed dos placeholders e roda o otmizador e retorna o erro\n",
        "        _, custo =sess.run([otimizador, erro], feed_dict = {xph: x, yph: y})\n",
        "        #a cada 200 epocas ou o erro médio ser zero calcula o erro médio\n",
        "        if (epocas % 200 == 0) or (erro_medio == 0):\n",
        "            #calcula o erro médio para cada saída\n",
        "            erro_medio += custo/4\n",
        "            #incrementa as épocas\n",
        "            epocas+=1    \n",
        "            #print('Epoca: ', epocas, ' -> Erro Médio: ', erro_medio)\n",
        "    #salva os pesos finais e o bias final        \n",
        "    w_final, b_final = sess.run([w,b]) \n",
        "    \n",
        "#formulas teste de rede\n",
        "camada_oculta_teste = tf.add(tf.matmul(xph,w_final['oculta']),b_final['oculta'])\n",
        "camada_oculta_ativacao_teste = tf.sigmoid(camada_oculta_teste)\n",
        "camada_saida_teste = tf.add(tf.matmul(camada_oculta_ativacao_teste, w_final['saida']),b_final['saida'])\n",
        "camada_saida_ativacao_teste = tf.sigmoid(camada_saida_teste)\n",
        "#print(camada_saida_ativacao_teste)\n",
        "\n",
        "feed_dict_test = {xph: x}\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    #execução da rede de teste\n",
        "    yph = sess.run(camada_saida_ativacao_teste, feed_dict=feed_dict_test)\n",
        "    print(yph)\n",
        "    \n",
        "    writer = tf.summary.FileWriter(save_pb, sess.graph)\n",
        "\n",
        "    #nome do arquivo de salvamento de log e faz a saida em formato .pbtxt\n",
        "    filename = 'my_test_model'\n",
        "   \n",
        "    # Exporta o checkpoint para SavedModel\n",
        "    #salva o grafo e eventos da sessão em arquivos de log \n",
        "    train_writer = tf.summary.FileWriter(save_pb, sess.graph)\n",
        "    #exporta para formato .pb\n",
        "    tf.train.write_graph(tf.GraphDef(), save_pb,filename+'.pb', as_text=False)\n",
        "    test_summary_writer = tf.summary.FileWriter(save_log, sess.graph) \n",
        "    \n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0705 15:16:14.055882 139890394916736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.12523778]\n",
            " [0.75896513]\n",
            " [0.83248574]\n",
            " [0.24093248]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}